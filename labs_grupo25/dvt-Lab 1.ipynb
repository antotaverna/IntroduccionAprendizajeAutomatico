{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 1: Regresión en California\n",
    "\n",
    "En este laboratorio deben hacer experimentos de regresión con el conjunto de datos \"California Housing dataset\".\n",
    "\n",
    "Estudiarán el dataset, harán visualizaciones y seleccionarán atributos relevantes a mano.\n",
    "\n",
    "Luego, entrenarán y evaluarán diferentes tipos de regresiones, buscando las configuraciones que mejores resultados den."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del Conjunto de Datos\n",
    "\n",
    "Cargamos el conjunto de datos y vemos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X_california, y_california = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "california = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vistazo a la Estructura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(california['DESCR'])  # descripción del dataset\n",
    "#california['feature_names'] # nombres de los atributos para cada columna de 'data'\n",
    "#california['data']           # matriz con los datos de entrada (atributos)\n",
    "#print(california['target']) # vector de valores a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california['data'].shape, california['target'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada fila representa un distrito, o \"block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_california.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_california.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Información sobre los datos con `pd.DataFrame.info()` \\\n",
    "Hay 20640 registros, con 8 atributos, todo numéricos y ninguno tiene datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_california.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción de los atributos numéricos con `pd.DataFrame.describe()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_california.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograma de los atributos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `MedInc` está expresado en una moneda que no parece ser dólares. Investigando sobre el data set vemos que \"1\" significa más o menos USD 10K de Median Income\n",
    "2. `HouseAge` y `MedHouseVal` (la variable que quiero predecir) están cortadas en un valor máximo\n",
    "3. Las dimensiones de los atributos tienen escalas muy distintas\n",
    "4. Muchos atributos (`AveRooms`, `AveBedrms`, `Population`y `AveOccup`) tienen distribuciones muy sesgadas hacia la izquierda. Muchos valores bajos y pocos valores altos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "X_california.hist(bins=50, figsize=(20,15)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_california.hist(bins=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División en Entrenamiento y Evaluación\n",
    "\n",
    "Dividimos aleatoriamente los datos en 80% para entrenamiento y 20% para evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = california['data'], california['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Responda las siguientes preguntas:\n",
    "\n",
    "1. ¿De qué se trata el conjunto de datos?\n",
    "2. ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?\n",
    "3. ¿Qué información (atributos) hay disponibles para hacer la predicción?\n",
    "4. ¿Qué atributos imagina ud. que serán los más determinantes para la predicción?\n",
    "5. ¿Qué problemas observa a priori en el conjunto de datos? ¿Observa posibles sesgos, riesgos, dilemas éticos, etc? Piense que los datos pueden ser utilizados para hacer predicciones futuras.\n",
    "\n",
    "**No hace falta escribir código para responder estas preguntas.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Responder todas las preguntas acá.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Visualización de los Datos\n",
    "\n",
    "1. Para cada atributo de entrada, haga una gráfica que muestre su relación con la variable objetivo.\n",
    "2. Estudie las gráficas, identificando **a ojo** los atributos que a su criterio sean los más informativos para la predicción.\n",
    "3. Para ud., ¿cuáles son esos atributos? Lístelos en orden de importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california['feature_names']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteo la variable target en función de todas las features iterativamente.\\\n",
    "Uso `alpha=0.05` para añadir transparencia y ver mejor la densidad de puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in california['feature_names']:\n",
    "    selector = (np.array(california['feature_names']) == feature)\n",
    "    plt.scatter(X[:,selector], y, alpha=0.1, label='datos')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Inspección de atributos**\n",
    "\n",
    "El atributo más informativo parece ser el `MedInc` porque parece que la variable target cambia en función de esta variable que de las otras.\\"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Atributos más informativos**\n",
    "\n",
    "En órden de importancia `MedInc` y en menos medido `Latitude` y `Longitude`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Regresión Lineal\n",
    "\n",
    "1. Seleccione **un solo atributo** que considere puede ser el más apropiado.\n",
    "2. Instancie una regresión lineal de **scikit-learn**, y entrénela usando sólo el atributo seleccionado.\n",
    "3. Evalúe, calculando error cuadrático medio para los conjuntos de entrenamiento y evaluación.\n",
    "4. Grafique el modelo resultante, junto con los puntos de entrenamiento y evaluación.\n",
    "5. Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido.\n",
    "\n",
    "**Observación:** Con algunos atributos se puede obtener un error en test menor a 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Resolver acá. Ayuda:\n",
    "feature = 'MedInc'\n",
    "#selector = california['feature_names'].index(feature)\n",
    "selector = (np.array(california['feature_names']) ==  feature)\n",
    "X_train_f = X_train[:, selector]\n",
    "X_test_f = X_test[:, selector]\n",
    "X_train_f.shape, X_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instanciar y entrenar acá.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un RMSE de 8420 significa que en promedio mis prediciones en este modelo estuvieron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# predicciones para el set de entrenamiento\n",
    "y_train_pred_f = lin_reg.predict(X_train_f)\n",
    "\n",
    "# predicciones para el set de testeo\n",
    "y_pred_f = lin_reg.predict(X_test_f)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_f))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_f))\n",
    "\n",
    "print(f'RMSE de entrenamiento (USD): {train_rmse * 1e4}')\n",
    "print(f'RMS de testeo (USD): {test_rmse * 1e4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Graficar acá. Ayuda:\n",
    "x_start = min(np.min(X_train_f), np.min(X_test_f))\n",
    "x_end = max(np.max(X_train_f), np.max(X_test_f))\n",
    "x = np.linspace(x_start, x_end, 200).reshape(-1, 1)\n",
    "plt.plot(x, lin_reg.predict(x), color=\"tomato\", label=\"modelo\")\n",
    "\n",
    "plt.scatter(X_train_f, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"train\")\n",
    "plt.scatter(X_test_f, y_test, facecolor=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "plt.title(feature)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Interpretación**\n",
    "\n",
    "El modelo no es muy bueno, con un RMSE de 6900 USD en entrenamiendo y 7000 dolares en testeo.\\\n",
    "Al ser similares los errores de entramiento y testeo me indica que no hay sobreajuste (overfitting).\\\n",
    "En promedio el modelo tiene un error de 7000 USD, lo cual no es muy bueno."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Regresión Polinomial\n",
    "\n",
    "En este ejercicio deben entrenar regresiones polinomiales de diferente complejidad, siempre usando **scikit-learn**.\n",
    "\n",
    "Deben usar **el mismo atributo** seleccionado para el ejercicio anterior.\n",
    "\n",
    "1. Para varios grados de polinomio, haga lo siguiente:\n",
    "    1. Instancie y entrene una regresión polinomial.\n",
    "    2. Prediga y calcule error en entrenamiento y evaluación. Imprima los valores.\n",
    "    3. Guarde los errores en una lista.\n",
    "2. Grafique las curvas de error en términos del grado del polinomio.\n",
    "3. Interprete la curva, identificando el punto en que comienza a haber sobreajuste, si lo hay.\n",
    "4. Seleccione el modelo que mejor funcione, y grafique el modelo conjuntamente con los puntos.\n",
    "5. Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido.\n",
    "\n",
    "**Observación:** Con algunos atributos se pueden obtener errores en test menores a 40 e incluso a 35."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Para varios grados de polinomio, haga lo siguiente:\n",
    "    1. Instancie y entrene una regresión polinomial.\n",
    "    2. Prediga y calcule error en entrenamiento y evaluación. Imprima los valores.\n",
    "    3. Guarde los errores en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Crear las feautures polinomiales\n",
    "pf = PolynomialFeatures(5)  # Instanciar el generador de features polinomiales\n",
    "#pf.fit(X_train_f)  # Crear las features polinomiales\n",
    "\n",
    "X_train_f_poly = pf.fit_transform(X_train_f)\n",
    "X_train_f_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(1)\n",
    "lr = LinearRegression(fit_intercept=False)  # el bias term ya está como feature por polynomial features\n",
    "\n",
    "pf.fit_transform(X_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(pf, lr)\n",
    "model.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_rmse_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "degrees = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    pf = PolynomialFeatures(degree)\n",
    "    lr = LinearRegression(fit_intercept=False)  # el bias term ya está como feature por polynomial features\n",
    "\n",
    "    model = make_pipeline(pf, lr)\n",
    "    model.fit(X_train_f, y_train)\n",
    "    \n",
    "    print(f\"Coeficientes del modelo de polinomio {degree}: {model['linearregression'].coef_}\")\n",
    "\n",
    "    y_train_f_pred = model.predict(X_train_f)\n",
    "    y_test_f_pred = model.predict(X_test_f)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_f_pred)) * 1e4\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_f_pred)) * 1e4\n",
    "    \n",
    "    print(f'Train RMSE: {train_rmse}')\n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    x_start = min(np.min(X_train_f), np.min(X_test_f))\n",
    "    x_end = max(np.max(X_train_f), np.max(X_test_f))\n",
    "    x = np.linspace(x_start, x_end, 200).reshape(-1, 1)\n",
    "    plt.plot(x, model.predict(x), color=\"red\", label=\"modelo\")\n",
    "\n",
    "    plt.scatter(X_train_f, y_train, facecolor=\"dodgerblue\", label=\"train\", alpha=0.3, edgecolor=\"k\")\n",
    "    plt.scatter(X_test_f, y_test, facecolor=\"yellow\", label=\"test\", alpha=0.3, edgecolor=\"k\")\n",
    "    plt.title(f'{feature} poly {degree}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Graficar curvas de error acá.\n",
    "plt.plot(degrees, train_rmse_list, color=\"blue\", label=\"train\")\n",
    "plt.plot(degrees, test_rmse_list, color=\"red\", label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Interprete la curva, identificando el punto en que comienza a haber sobreajuste, si lo hay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Seleccione el modelo que mejor funcione, y grafique el modelo conjuntamente con los puntos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "5. Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Regresión con más de un Atributo\n",
    "\n",
    "En este ejercicio deben entrenar regresiones que toman más de un atributo de entrada.\n",
    "\n",
    "1. Seleccione **dos o tres atributos** entre los más relevantes encontrados en el ejercicio 2.\n",
    "2. Repita el ejercicio anterior, pero usando los atributos seleccionados. No hace falta graficar el modelo final.\n",
    "3. Interprete el resultado y compare con los ejercicios anteriores. ¿Se obtuvieron mejores modelos? ¿Porqué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Resolver acá. Ayuda (con dos atributos):\n",
    "selector = (np.array(california['feature_names']) == 'HouseAge') | (np.array(california['feature_names']) == 'AveRooms')\n",
    "\n",
    "X_train_fs = X_train[:, selector]\n",
    "X_test_fs = X_test[:, selector]\n",
    "X_train_fs.shape, X_test_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Resolver acá.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_rmse_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "degrees = [0, 1, 2, 3, 4]\n",
    "\n",
    "for degree in degrees:\n",
    "    \n",
    "    pf = PolynomialFeatures(degree)\n",
    "    lr = LinearRegression(fit_intercept=False)  # el bias term ya está como feature por polynomial features\n",
    "\n",
    "    model = make_pipeline(pf, lr)\n",
    "    model.fit(X_train_fs, y_train)\n",
    "    \n",
    "    print(f\"Coeficientes del modelo de polinomio {degree}: {model['linearregression'].coef_}\")\n",
    "\n",
    "    y_train_fs_pred = model.predict(X_train_fs)\n",
    "    y_test_fs_pred = model.predict(X_test_fs)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_fs_pred)) * 1e4\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_fs_pred)) * 1e4\n",
    "    \n",
    "    print(f'Train RMSE: {train_rmse}')\n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Graficar curvas de error acá.\n",
    "plt.plot(degrees, train_rmse_list, color=\"blue\", label=\"train\")\n",
    "plt.plot(degrees, test_rmse_list, color=\"red\", label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Responder acá.**\n",
    "\n",
    "Cuando usamos dos variables o muchas más (con sus versiones polinómicas) el modelo sobreajusta rápidamente luego de ser entrenado con las features de polinomio tres. Lo podemos ver porque la RMSE de entrenamiento es baja mientras que la RMSE de test es cada vez más alta.\n",
    "\n",
    "De hecho ningún modelo de esta versión con más de una variable logra RMSE mejores que el mejor modelo de una variable. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Más ejercicios (opcionales)\n",
    "\n",
    "### Ejercicio 6: A Todo Feature\n",
    "\n",
    "Entrene y evalúe regresiones pero utilizando todos los atributos de entrada (va a andar mucho más lento). Estudie los resultados.\n",
    "\n",
    "### Ejercicio 7: Regularización\n",
    "\n",
    "Entrene y evalúe regresiones con regularización \"ridge\". Deberá probar distintos valores de \"alpha\" (fuerza de la regularización). ¿Mejoran los resultados?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
